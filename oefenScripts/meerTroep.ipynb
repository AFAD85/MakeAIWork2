{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import requests\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anton\\MakeAIWork2\\projects\\apple_disease_classification\\data\\Train\\Blotch_Apple\\10.jpg\n"
     ]
    }
   ],
   "source": [
    "trainBlotchDirectory = Path('C:/Users/Anton/MakeAIWork2/projects/apple_disease_classification/data/Train/Blotch_Apple')\n",
    "trainNormalDirectory = Path('C:/Users/Anton/MakeAIWork2/projects/apple_disease_classification/data/Train/Normal_Apple')\n",
    "trainRotDirectory = Path('C:/Users/Anton/MakeAIWork2/projects/apple_disease_classification/data/Train/Rot_Apple')\n",
    "trainScabDirectory = Path('C:/Users/Anton/MakeAIWork2/projects/apple_disease_classification/data/Train/Scab_Apple')\n",
    "\n",
    "edgeFiles = list()\n",
    "imageList = list()\n",
    "for filename in os.listdir(trainBlotchDirectory):\n",
    "    imgFile = os.path.join(trainBlotchDirectory, filename)\n",
    "    edgeFiles.append(imgFile)\n",
    "\n",
    "for filename in os.listdir(trainNormalDirectory):\n",
    "    imgFile = os.path.join(trainNormalDirectory, filename)\n",
    "    edgeFiles.append(imgFile)\n",
    "\n",
    "for filename in os.listdir(trainRotDirectory):\n",
    "    imgFile = os.path.join(trainRotDirectory, filename)\n",
    "    edgeFiles.append(imgFile)\n",
    "\n",
    "for filename in os.listdir(trainScabDirectory):\n",
    "    imgFile = os.path.join(trainScabDirectory, filename)\n",
    "    edgeFiles.append(imgFile)\n",
    "\n",
    "print(edgeFiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Anton/MakeAIWork2/projects/apple_disease_classification/data/Train/Blotch_Apple/10.jpg\n"
     ]
    }
   ],
   "source": [
    "edgeFiles = [files.replace(\"\\\\\",\"/\") for files in edgeFiles]\n",
    "edgeFiles = [img for img in edgeFiles if \".jpg\" in img]\n",
    "\n",
    "print(edgeFiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (575,767,3) into shape (64,64,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [17], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m pic \u001b[39min\u001b[39;00m edgeFiles:\n\u001b[1;32m----> 6\u001b[0m   imageObjects[i] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(Image\u001b[39m.\u001b[39mopen(pic))\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m\n\u001b[0;32m      7\u001b[0m   i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (575,767,3) into shape (64,64,3)"
     ]
    }
   ],
   "source": [
    "imageObjects = np.zeros([len(edgeFiles), 64, 64, 3])\n",
    "\n",
    "i = 0\n",
    "\n",
    "for pic in edgeFiles:\n",
    "  imageObjects[i] = np.asarray(Image.open(pic)).astype('uint8')/255\n",
    "  i += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageLabels = np.empty(len(edgeFiles), dtype = 'S20')\n",
    "\n",
    "i = 0\n",
    "\n",
    "for label in edgeFiles:\n",
    "    edgeFiles[i] = label.split('/')[1]\n",
    "    i += 1\n",
    "    \n",
    "\n",
    "labelNames, labelNumbers = np.unique(edgeFiles, return_inverse=True)\n",
    "labelDict = dict(zip(np.unique(labelNumbers), labelNames))\n",
    "print(labelNames)\n",
    "print(labelNumbers)\n",
    "\n",
    "np.array(np.unique(labelNumbers, return_counts=True)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspectData():\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    \n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(imageObjects[i])\n",
    "        plt.xlabel(labelNames[labelNumbers[i]]) \n",
    "\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspectData() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(labelNames)\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(64, 64, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(num_classes))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFunction = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "gdAlgorithm = keras.optimizers.Adam(learning_rate=0.001)\n",
    "nrOfEpochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=gdAlgorithm, loss=lossFunction, metrics=\"accuracy\")\n",
    "history = model.fit(trainSet, trainLabels, epochs=nrOfEpochs, batch_size=64, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=gdAlgorithm, loss=lossFunction, metrics=\"accuracy\")\n",
    "history_test = model.fit(testSet, testLabels, epochs=nrOfEpochs, batch_size=64, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet, testSet, trainLabels, testLabels = train_test_split(imageObjects, labelNumbers, stratify = labelNumbers, train_size = 0.75, random_state=42)\n",
    "print(trainSet.shape)\n",
    "nrOfImages = len(trainSet)\n",
    "print(nrOfImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hier kies je welke index je iets mee wilt\n",
    "i = 10\n",
    "\n",
    "#dit is het plaatje van index i\n",
    "img = trainSet[i]\n",
    "\n",
    "# print de label naam van index i\n",
    "print(labelNames[trainLabels[i]])\n",
    "\n",
    "#laat plaatje zien\n",
    "plt.imshow(img);\n",
    "\n",
    "#iets met predict doen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get predictions\n",
    "pred = model.predict(testSet, batch_size=16)\n",
    "pred = np.argmax(pred, axis=-1)\n",
    "\n",
    "#original labels\n",
    "labels = np.argmax(testLabels,axis=-1)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(labels, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "343175793893d94ad600fed4205d39857cd4175d02ecc054914f6e7a2056793d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
