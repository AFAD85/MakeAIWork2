{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"T6h9WQpswlce"},"outputs":[],"source":["import torch\n","import os\n","import numpy as np\n","import glob\n","import torch.nn as nn\n","from torchvision.transforms import transforms\n","from torch.utils.data import DataLoader #let op dubbele hoofdletter\n","from torch.optim import Adam\n","# from torch.autograd import Variable \n","# deprecated, uit code gehaald, wordt niet meer gebruikt\n","import torchvision\n","import pathlib\n","from pathlib import Path\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"cvW_OGbFwlci"},"outputs":[],"source":["# doet cuda het?\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"8oEtCTe6wlck","outputId":"ce4ea365-e5bd-4216-9ba5-a4c6cf3fe0b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["print(device)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"TsYTqKUUwlcr"},"outputs":[],"source":["# transforms instellen (hier zou je de pipeline aanmaken stel dat je dat wil, vind het zelf onhandig en onvoorspelbaar)\n","transformer = transforms.Compose([\n","    transforms.Resize((350,350)),\n","    transforms.ToTensor(),#tensortjes maken zodat torch er mee om kan gaan (zet ook pixel waarden tussen 0 en 1)\n","    transforms.Normalize([0.5,0.5,0.5],\n","                         [0.5,0.5,0.5]).cuda()\n","])#deze termen zorgen voor transformatie naar -1 , 1 dit zou beter moeten zijn voor het trainen, ik weet niet waarom\n","    \n","    \n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"TgfjlMZowlcr"},"outputs":[{"ename":"FileNotFoundError","evalue":"[WinError 3] The system cannot find the path specified: 'data_augmented_colorLUV2RGB'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn [5], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# data inladen (dataloader instellen)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m train_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdata_augmented_colorLUV2RGB\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      4\u001b[0m train_loader\u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m----> 5\u001b[0m     torchvision\u001b[39m.\u001b[39;49mdatasets\u001b[39m.\u001b[39;49mImageFolder(train_path, transform \u001b[39m=\u001b[39;49m transformer),\n\u001b[0;32m      6\u001b[0m     batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m test_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mapple_disease_classification\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mTest\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     11\u001b[0m test_loader\u001b[39m=\u001b[39m DataLoader(\n\u001b[0;32m     12\u001b[0m     torchvision\u001b[39m.\u001b[39mdatasets\u001b[39m.\u001b[39mImageFolder(test_path, transform \u001b[39m=\u001b[39m transformer),\n\u001b[0;32m     13\u001b[0m     batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     14\u001b[0m )\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py:309\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    302\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    303\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    307\u001b[0m     is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    308\u001b[0m ):\n\u001b[1;32m--> 309\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m    310\u001b[0m         root,\n\u001b[0;32m    311\u001b[0m         loader,\n\u001b[0;32m    312\u001b[0m         IMG_EXTENSIONS \u001b[39mif\u001b[39;49;00m is_valid_file \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    313\u001b[0m         transform\u001b[39m=\u001b[39;49mtransform,\n\u001b[0;32m    314\u001b[0m         target_transform\u001b[39m=\u001b[39;49mtarget_transform,\n\u001b[0;32m    315\u001b[0m         is_valid_file\u001b[39m=\u001b[39;49mis_valid_file,\n\u001b[0;32m    316\u001b[0m     )\n\u001b[0;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimgs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msamples\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py:144\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    135\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    136\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m     is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    142\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(root, transform\u001b[39m=\u001b[39mtransform, target_transform\u001b[39m=\u001b[39mtarget_transform)\n\u001b[1;32m--> 144\u001b[0m     classes, class_to_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_classes(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot)\n\u001b[0;32m    145\u001b[0m     samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_dataset(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[0;32m    147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader \u001b[39m=\u001b[39m loader\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py:218\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_classes\u001b[39m(\u001b[39mself\u001b[39m, directory: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[List[\u001b[39mstr\u001b[39m], Dict[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m]]:\n\u001b[0;32m    192\u001b[0m     \u001b[39m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \n\u001b[0;32m    194\u001b[0m \u001b[39m        directory/\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[39m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 218\u001b[0m     \u001b[39mreturn\u001b[39;00m find_classes(directory)\n","File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py:40\u001b[0m, in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_classes\u001b[39m(directory: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[List[\u001b[39mstr\u001b[39m], Dict[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m]]:\n\u001b[0;32m     36\u001b[0m     \u001b[39m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[39m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     classes \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(entry\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m entry \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mscandir(directory) \u001b[39mif\u001b[39;00m entry\u001b[39m.\u001b[39mis_dir())\n\u001b[0;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m classes:\n\u001b[0;32m     42\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find any class folder in \u001b[39m\u001b[39m{\u001b[39;00mdirectory\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n","\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'data_augmented_colorLUV2RGB'"]}],"source":["# data inladen (dataloader instellen)\n","train_path = 'data_augmented_colorLUV2RGB'\n","\n","train_loader= DataLoader(\n","    torchvision.datasets.ImageFolder(train_path, transform = transformer),\n","    batch_size=32, shuffle=True\n",")\n","\n","test_path = 'apple_disease_classification\\Test'\n","\n","test_loader= DataLoader(\n","    torchvision.datasets.ImageFolder(test_path, transform = transformer),\n","    batch_size=32, shuffle=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AEKVSSe8wlcs"},"outputs":[],"source":["# klassen/labels halen\n","root = Path(train_path)\n","classes = sorted([j.name.split('/')[-1] for j in root.iterdir()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WY9kRKUTwlct","outputId":"24637744-7432-4532-90ef-8ae52cfd442c"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Blotch_Apple', 'Normal_Apple', 'Rot_Apple', 'Scab_Apple']\n"]}],"source":["# gelukt?\n","print(classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ugfTTkymwlcu"},"outputs":[],"source":["# model bouwen \n","# input shape wordt : (32,3,350,350) (batchsize, rgb, dimensions)\n","# batch normalization komt er op neer dat je verspreiding van de range van data steeds weer inkrimpt om het rekenen binnen perken te houden https://arxiv.org/abs/1502.03167\n","\n","class ConvNet(nn.Module):\n","    def __init__(self,num_classes=4):\n","        super(ConvNet,self).__init__()\n","        \n","        self.conv1 = nn.Conv2d(in_channels=3,out_channels=128,kernel_size=3,stride=1,padding='valid')\n","        self.bn1 = nn.BatchNorm2d(num_features=128)\n","        self.relu1 = nn.ReLU()\n","        self.pool1 = nn.MaxPool2d(kernel_size=2)\n","        \n","        self.conv2 = nn.Conv2d(in_channels=128,out_channels=64,kernel_size=3,stride=1,padding='valid')\n","        self.bn2 = nn.BatchNorm2d(num_features=64)\n","        self.relu2 = nn.ReLU()\n","        self.pool2 = nn.MaxPool2d(kernel_size=2)\n","        \n","        self.conv3 = nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,stride=1,padding='valid')\n","        self.bn3 = nn.BatchNorm2d(num_features=64)\n","        self.relu3 = nn.ReLU()\n","        self.pool3 = nn.MaxPool2d(kernel_size=2)\n","        \n","        self.conv4 = nn.Conv2d(in_channels=64,out_channels=32,kernel_size=3,stride=1,padding='valid')\n","        self.bn4 = nn.BatchNorm2d(num_features=32)\n","        self.relu4 = nn.ReLU()\n","        self.pool4 = nn.MaxPool2d(kernel_size=2)\n","        \n","        self.conv5 = nn.Conv2d(in_channels=32,out_channels=32,kernel_size=3,stride=1,padding='valid')\n","        self.bn5 = nn.BatchNorm2d(num_features=32)\n","        self.relu5 = nn.ReLU()\n","        self.pool5 = nn.MaxPool2d(kernel_size=2)\n","        \n","        self.flat = nn.Flatten()\n","        self.fc1 = nn.Linear(in_features=2592, out_features = 256,device=device)\n","        self.dropout1 = nn.Dropout(0.25)\n","        self.fc2 = nn.Linear(in_features=256, out_features = num_classes,device=device)\n","        self.dropout2 = nn.Dropout(0.25)\n","\n","        \n","    def forward(self,input):\n","        output = self.conv1(input)\n","        output = self.bn1(output)\n","        output = self.relu1(output)\n","        output = self.pool1(output)\n","        \n","        output = self.conv2(output)\n","        output = self.bn2(output)\n","        output = self.relu2(output)\n","        output = self.pool2(output)\n","        \n","        output = self.conv3(output)\n","        output = self.bn3(output)\n","        output = self.relu3(output)\n","        output = self.pool3(output)\n","        \n","        output = self.conv4(output)\n","        output = self.bn4(output)\n","        output = self.relu4(output)\n","        output = self.pool4(output)\n","        \n","        output = self.conv5(output)\n","        output = self.bn5(output)\n","        output = self.relu5(output)\n","        output = self.pool5(output)\n","        \n","        # output = output.view(-1,32,9,9)\n","        \n","        output = self.flat(output)\n","        output = self.dropout1(self.fc1(output))\n","        output = self.dropout2(self.fc2(output))\n","        \n","        return output\n","        \n","        # als het goed is komt hier een matrix uit"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SZ0JoPJPwlcy"},"outputs":[],"source":["# model op de hardware laden\n","model = ConvNet(num_classes=4).to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CTGh0Ltrwlc0"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MjwGhHjewlc1"},"outputs":[],"source":["#optimaaaizer en loss function\n","optimizer = Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n","loss_function = nn.CrossEntropyLoss().cuda()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oK0W1oSqwlc2"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dIgkkI4lwlc3"},"outputs":[],"source":["num_epochs = 100\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2iuWYaaAwlc3"},"outputs":[],"source":["# checken hoeveel bestanden we hebben voor train en test (alle bestanden)\n","train_count = len(glob.glob(train_path+'/**/*.*'))\n","test_count = len(glob.glob(test_path+'/**/*.*'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RavJcdpdwlc4","outputId":"a7a3d066-715a-4858-d0f6-1ccdc2703b85"},"outputs":[{"name":"stdout","output_type":"stream","text":["382 120\n"]}],"source":["print(train_count, test_count)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"27c-Rqc1wlc4","outputId":"2ad3041e-248d-4727-87ed-71ae49cb64ae"},"outputs":[{"data":{"text/plain":["[device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0)]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["list(map(lambda x: x.device, model.parameters()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"95NvPSftwlc5","outputId":"8a7c6dc8-9ffb-4334-fc79-2b3af1eeabf5"},"outputs":[{"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 3.18 GiB (GPU 0; 8.00 GiB total capacity; 6.43 GiB already allocated; 41.00 MiB free; 6.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2628\\4196674351.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32ma:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2628\\4258986033.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32ma:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32ma:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32ma:\\Anaconda\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1455\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1457\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1458\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.18 GiB (GPU 0; 8.00 GiB total capacity; 6.43 GiB already allocated; 41.00 MiB free; 6.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["# trainen en opslaan\n","\n","best_accuracy = 0.0\n","\n","for epoch in range(num_epochs):\n","    \n","    model.train()\n","    train_accuracy = 0.0\n","    train_loss = 0.0\n","    \n","    for i, (images,labels) in enumerate(train_loader):\n","        if torch.cuda.is_available():\n","    # zorgen dat de bestanden via de gpu gaan als die beschikbaar is\n","            images = images.cuda()\n","            labels = labels.cuda()\n","# zorgt dat de optimizer niet verward raakt door mixen van resultaat per batch        \n","        optimizer.zero_grad()\n","\n","        outputs = model(images)\n","        loss = loss_function(outputs,labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.cpu().data*images.size(0)\n","        _,prediction = torch.max(outputs.data,1)\n","    \n","        train_accuracy += int(torch.sum(prediction==labels.data))\n","\n","    train_accuracy = train_accuracy/train_count\n","    train_loss = train_loss/train_count\n","    \n","    #test set evalueren\n","    model.eval()\n","    \n","    test_accuracy = 0.0\n","    for i, (images,labels) in enumerate(test_loader):\n","        if torch.cuda.is_available():\n","            images = Variable(images.cuda())\n","            labels = Variable(labels.cuda())\n","        \n","        outputs = model(images)\n","        _, prediction = torch.max(outputs.data,1)\n","        test_accuracy += int(torch.sum(prediction==labels.data))\n","        \n","    test_accuracy = test_accuracy/test_count\n","\n","    print('Epoch: '+str(epoch)+' Train Loss: '+str(int(train_loss))+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n","\n","    # model opslaan als beste is van getraint        \n","    if test_accuracy > best_accuracy:\n","        torch.save(model.state_dict(), 'best_checkpoint.model')\n","        best_accuracy = test_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yh6WQNzSwlc6","outputId":"fef6ee27-dc09-4ade-f85d-6375ecca3fbc"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.7083333333333334\n"]}],"source":["print(best_accuracy)\n","# print(model.get_parameters())\n","# print(model)\n","# list(map(lambda x: x.device, model.parameters()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Z-paQ6bwlc8"},"outputs":[],"source":["# Hoogst behaald: 0.7333333333333333 - standaard dataset\n","#  - gelijk aantal per klasse, flipped"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-v9_xST9wlc8"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cRZI4adtwlc8"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qg1dIsWgwlc9"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.9.13 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"}}},"nbformat":4,"nbformat_minor":0}
