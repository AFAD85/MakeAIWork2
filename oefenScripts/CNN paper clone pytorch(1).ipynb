{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"T6h9WQpswlce"},"outputs":[],"source":["import torch\n","import os\n","import numpy as np\n","import glob\n","import torch.nn as nn\n","from torchvision.transforms import transforms\n","from torch.utils.data import DataLoader #let op dubbele hoofdletter\n","from torch.optim import Adam\n","# from torch.autograd import Variable \n","# deprecated, uit code gehaald, wordt niet meer gebruikt\n","import torchvision\n","import pathlib\n","from pathlib import Path\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cvW_OGbFwlci"},"outputs":[],"source":["# doet cuda het?\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8oEtCTe6wlck","outputId":"ce4ea365-e5bd-4216-9ba5-a4c6cf3fe0b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TsYTqKUUwlcr"},"outputs":[],"source":["# transforms instellen (hier zou je de pipeline aanmaken stel dat je dat wil, vind het zelf onhandig en onvoorspelbaar)\n","transformer = transforms.Compose([\n","    transforms.Resize((350,350)),\n","    transforms.ToTensor(),#tensortjes maken zodat torch er mee om kan gaan (zet ook pixel waarden tussen 0 en 1)\n","    transforms.Normalize([0.5,0.5,0.5],\n","                         [0.5,0.5,0.5]).cuda()\n","])#deze termen zorgen voor transformatie naar -1 , 1 dit zou beter moeten zijn voor het trainen, ik weet niet waarom\n","    \n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TgfjlMZowlcr"},"outputs":[],"source":["# data inladen (dataloader instellen)\n","train_path = 'data_augmented_colorLUV2RGB'\n","\n","train_loader= DataLoader(\n","    torchvision.datasets.ImageFolder(train_path, transform = transformer),\n","    batch_size=32, shuffle=True\n",")\n","\n","test_path = 'apple_disease_classification\\Test'\n","\n","test_loader= DataLoader(\n","    torchvision.datasets.ImageFolder(test_path, transform = transformer),\n","    batch_size=32, shuffle=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AEKVSSe8wlcs"},"outputs":[],"source":["# klassen/labels halen\n","root = Path(train_path)\n","classes = sorted([j.name.split('/')[-1] for j in root.iterdir()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WY9kRKUTwlct","outputId":"24637744-7432-4532-90ef-8ae52cfd442c"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Blotch_Apple', 'Normal_Apple', 'Rot_Apple', 'Scab_Apple']\n"]}],"source":["# gelukt?\n","print(classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ugfTTkymwlcu"},"outputs":[],"source":["# model bouwen \n","# input shape wordt : (32,3,350,350) (batchsize, rgb, dimensions)\n","# batch normalization komt er op neer dat je verspreiding van de range van data steeds weer inkrimpt om het rekenen binnen perken te houden https://arxiv.org/abs/1502.03167\n","\n","class ConvNet(nn.Module):\n","    def __init__(self,num_classes=4):\n","        super(ConvNet,self).__init__()\n","        \n","        self.conv1 = nn.Conv2d(in_channels=3,out_channels=128,kernel_size=3,stride=1,padding='valid')\n","        self.bn1 = nn.BatchNorm2d(num_features=128)\n","        self.relu1 = nn.ReLU()\n","        self.pool1 = nn.MaxPool2d(kernel_size=2)\n","        \n","        self.conv2 = nn.Conv2d(in_channels=128,out_channels=64,kernel_size=3,stride=1,padding='valid')\n","        self.bn2 = nn.BatchNorm2d(num_features=64)\n","        self.relu2 = nn.ReLU()\n","        self.pool2 = nn.MaxPool2d(kernel_size=2)\n","        \n","        self.conv3 = nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,stride=1,padding='valid')\n","        self.bn3 = nn.BatchNorm2d(num_features=64)\n","        self.relu3 = nn.ReLU()\n","        self.pool3 = nn.MaxPool2d(kernel_size=2)\n","        \n","        self.conv4 = nn.Conv2d(in_channels=64,out_channels=32,kernel_size=3,stride=1,padding='valid')\n","        self.bn4 = nn.BatchNorm2d(num_features=32)\n","        self.relu4 = nn.ReLU()\n","        self.pool4 = nn.MaxPool2d(kernel_size=2)\n","        \n","        self.conv5 = nn.Conv2d(in_channels=32,out_channels=32,kernel_size=3,stride=1,padding='valid')\n","        self.bn5 = nn.BatchNorm2d(num_features=32)\n","        self.relu5 = nn.ReLU()\n","        self.pool5 = nn.MaxPool2d(kernel_size=2)\n","        \n","        self.flat = nn.Flatten()\n","        self.fc1 = nn.Linear(in_features=2592, out_features = 256,device=device)\n","        self.dropout1 = nn.Dropout(0.25)\n","        self.fc2 = nn.Linear(in_features=256, out_features = num_classes,device=device)\n","        self.dropout2 = nn.Dropout(0.25)\n","\n","        \n","    def forward(self,input):\n","        output = self.conv1(input)\n","        output = self.bn1(output)\n","        output = self.relu1(output)\n","        output = self.pool1(output)\n","        \n","        output = self.conv2(output)\n","        output = self.bn2(output)\n","        output = self.relu2(output)\n","        output = self.pool2(output)\n","        \n","        output = self.conv3(output)\n","        output = self.bn3(output)\n","        output = self.relu3(output)\n","        output = self.pool3(output)\n","        \n","        output = self.conv4(output)\n","        output = self.bn4(output)\n","        output = self.relu4(output)\n","        output = self.pool4(output)\n","        \n","        output = self.conv5(output)\n","        output = self.bn5(output)\n","        output = self.relu5(output)\n","        output = self.pool5(output)\n","        \n","        # output = output.view(-1,32,9,9)\n","        \n","        output = self.flat(output)\n","        output = self.dropout1(self.fc1(output))\n","        output = self.dropout2(self.fc2(output))\n","        \n","        return output\n","        \n","        # als het goed is komt hier een matrix uit"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SZ0JoPJPwlcy"},"outputs":[],"source":["# model op de hardware laden\n","model = ConvNet(num_classes=4).to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CTGh0Ltrwlc0"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MjwGhHjewlc1"},"outputs":[],"source":["#optimaaaizer en loss function\n","optimizer = Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n","loss_function = nn.CrossEntropyLoss().cuda()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oK0W1oSqwlc2"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dIgkkI4lwlc3"},"outputs":[],"source":["num_epochs = 100\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2iuWYaaAwlc3"},"outputs":[],"source":["# checken hoeveel bestanden we hebben voor train en test (alle bestanden)\n","train_count = len(glob.glob(train_path+'/**/*.*'))\n","test_count = len(glob.glob(test_path+'/**/*.*'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RavJcdpdwlc4","outputId":"a7a3d066-715a-4858-d0f6-1ccdc2703b85"},"outputs":[{"name":"stdout","output_type":"stream","text":["382 120\n"]}],"source":["print(train_count, test_count)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"27c-Rqc1wlc4","outputId":"2ad3041e-248d-4727-87ed-71ae49cb64ae"},"outputs":[{"data":{"text/plain":["[device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0),\n"," device(type='cuda', index=0)]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["list(map(lambda x: x.device, model.parameters()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"95NvPSftwlc5","outputId":"8a7c6dc8-9ffb-4334-fc79-2b3af1eeabf5"},"outputs":[{"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 3.18 GiB (GPU 0; 8.00 GiB total capacity; 6.43 GiB already allocated; 41.00 MiB free; 6.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2628\\4196674351.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32ma:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2628\\4258986033.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32ma:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32ma:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32ma:\\Anaconda\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1455\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1457\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1458\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.18 GiB (GPU 0; 8.00 GiB total capacity; 6.43 GiB already allocated; 41.00 MiB free; 6.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["# trainen en opslaan\n","\n","best_accuracy = 0.0\n","\n","for epoch in range(num_epochs):\n","    \n","    model.train()\n","    train_accuracy = 0.0\n","    train_loss = 0.0\n","    \n","    for i, (images,labels) in enumerate(train_loader):\n","        if torch.cuda.is_available():\n","    # zorgen dat de bestanden via de gpu gaan als die beschikbaar is\n","            images = images.cuda()\n","            labels = labels.cuda()\n","# zorgt dat de optimizer niet verward raakt door mixen van resultaat per batch        \n","        optimizer.zero_grad()\n","\n","        outputs = model(images)\n","        loss = loss_function(outputs,labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.cpu().data*images.size(0)\n","        _,prediction = torch.max(outputs.data,1)\n","    \n","        train_accuracy += int(torch.sum(prediction==labels.data))\n","\n","    train_accuracy = train_accuracy/train_count\n","    train_loss = train_loss/train_count\n","    \n","    #test set evalueren\n","    model.eval()\n","    \n","    test_accuracy = 0.0\n","    for i, (images,labels) in enumerate(test_loader):\n","        if torch.cuda.is_available():\n","            images = Variable(images.cuda())\n","            labels = Variable(labels.cuda())\n","        \n","        outputs = model(images)\n","        _, prediction = torch.max(outputs.data,1)\n","        test_accuracy += int(torch.sum(prediction==labels.data))\n","        \n","    test_accuracy = test_accuracy/test_count\n","\n","    print('Epoch: '+str(epoch)+' Train Loss: '+str(int(train_loss))+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n","\n","    # model opslaan als beste is van getraint        \n","    if test_accuracy > best_accuracy:\n","        torch.save(model.state_dict(), 'best_checkpoint.model')\n","        best_accuracy = test_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yh6WQNzSwlc6","outputId":"fef6ee27-dc09-4ade-f85d-6375ecca3fbc"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.7083333333333334\n"]}],"source":["print(best_accuracy)\n","# print(model.get_parameters())\n","# print(model)\n","# list(map(lambda x: x.device, model.parameters()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Z-paQ6bwlc8"},"outputs":[],"source":["# Hoogst behaald: 0.7333333333333333 - standaard dataset\n","#  - gelijk aantal per klasse, flipped"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-v9_xST9wlc8"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cRZI4adtwlc8"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qg1dIsWgwlc9"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.13 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"e654902f1877883cfc0f8194d1615c44937abe63f3bb0e0105192e55863f0170"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}