{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "818a1af7-9708-4bae-92fe-fa36b678d2be",
   "metadata": {},
   "source": [
    "<a href=\"https://it-omscholing.nl/locaties/hogeschool-rotterdam/\">\n",
    "<div>\n",
    "<a><img src='pics/banner.PNG'/></a>\n",
    "</div>\n",
    "<div>\n",
    "<a href=''><img src='pics/miw.PNG'/></a>\n",
    "<em>Author: Jeroen Boogaard</em>\n",
    "</div>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ff9227-1da2-489e-a4b4-d661d44ce68f",
   "metadata": {},
   "source": [
    "<h1>Practicum Computer Vision</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d395107",
   "metadata": {},
   "source": [
    "<h2>Imports<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d02a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow.keras as keras\n",
    "# import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72042f70-16c5-4a1a-a753-fc468bbe1a6a",
   "metadata": {},
   "source": [
    "**Stel TensorFlow in met loglevel 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86e675b9-244c-45c8-9c91-79146b304a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aae3d0-f644-4552-870c-029b41f24559",
   "metadata": {},
   "source": [
    "<h2>Data Collection</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170099a3-4baf-4d2b-9ee2-ba934e368432",
   "metadata": {},
   "source": [
    "<h3>Select Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "050810b9-7b7b-4290-b046-5b1b644ededd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  2 89.9M    2 2531k    0     0  8868k      0  0:00:10 --:--:--  0:00:10 8881k\n",
      " 34 89.9M   34 31.1M    0     0  24.2M      0  0:00:03  0:00:01  0:00:02 24.2M\n",
      " 63 89.9M   63 57.4M    0     0  25.1M      0  0:00:03  0:00:02  0:00:01 25.1M\n",
      " 91 89.9M   91 82.2M    0     0  25.0M      0  0:00:03  0:00:03 --:--:-- 25.0M\n",
      "100 89.9M  100 89.9M    0     0  25.1M      0  0:00:03  0:00:03 --:--:-- 25.1M\n"
     ]
    }
   ],
   "source": [
    "# !curl -L -o EuroSAT.zip https://madm.dfki.de/files/sentinel/EuroSAT.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57eb7d80-bfc1-4774-a635-fc28b2742aa0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot load file containing pickled data when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [24], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# datasetUrl = 'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz'\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# dataPath = keras.utils.get_file('flowerData',origin=datasetUrl,cache_dir='.', untar=True)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m path \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mget_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflowerData.tar.gz\u001b[39m\u001b[38;5;124m'\u001b[39m, datasetUrl)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m data:\n\u001b[0;32m      6\u001b[0m   train_examples \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_train\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m   train_labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_train\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\workspace\\MakeAIWork2\\env\\lib\\site-packages\\numpy\\lib\\npyio.py:418\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    416\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n\u001b[1;32m--> 418\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot load file containing pickled data \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen allow_pickle=False\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    421\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(fid, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_kwargs)\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot load file containing pickled data when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "# datasetUrl = 'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz'\n",
    "# dataPath = keras.utils.get_file('flowerData',origin=datasetUrl,cache_dir='.', untar=True)\n",
    "\n",
    "path = tf.keras.utils.get_file('flowerData.tar.gz', datasetUrl)\n",
    "with np.load(path) as data:\n",
    "  train_examples = data['x_train']\n",
    "  train_labels = data['y_train']\n",
    "  test_examples = data['x_test']\n",
    "  test_labels = data['y_test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9595fe-f581-46c5-b73f-f0ec2e58820b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9af14b2c-47b2-4256-9f22-715218d60b74",
   "metadata": {},
   "source": [
    "<h3>Split Data into Train and Test</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef3d2e75-c904-44f7-b764-618226c22dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_examples, train_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_examples, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dd8660-3828-442f-9df5-2b0a3f8f3bd7",
   "metadata": {},
   "source": [
    "<h3>Normalize Data</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f8f815-dbe0-481d-bb33-e6d0ef6ba5b3",
   "metadata": {},
   "source": [
    "**Normaliseer door alle waardes door de maximale waarde**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24cf059a-72ec-4347-b6f0-4130171d3ce5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'PrefetchDataset' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m maxImageValue \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[1;32m----> 2\u001b[0m trainSet \u001b[38;5;241m=\u001b[39m \u001b[43mtrainSet\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmaxImageValue\u001b[49m\n\u001b[0;32m      3\u001b[0m testSet \u001b[38;5;241m=\u001b[39m testSet \u001b[38;5;241m/\u001b[39m maxImageValue\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'PrefetchDataset' and 'int'"
     ]
    }
   ],
   "source": [
    "maxImageValue = 255\n",
    "trainSet = trainSet / maxImageValue\n",
    "testSet = testSet / maxImageValue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11669120-c3b7-4d62-8e61-e3858002d973",
   "metadata": {},
   "source": [
    "<h3>Visualise Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e3ce52-c40f-4225-8925-4f56df9b2cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspectData():\n",
    "    \n",
    "    # plt.figure(figsize(10,10))\n",
    "    \n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        imgplot = plt.imshow(trainSet[i])\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "inspectData()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b812bd6-f117-460f-9f8a-aa4fa2a5a4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
